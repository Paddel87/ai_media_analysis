name: Feature Testing
on:
  push:
    branches: [main, develop, feature/*]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.11'
  POETRY_VERSION: '1.7.1'

jobs:
  test-validation:
    name: Validate Test Requirements
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check for required tests
        id: check-tests
        run: |
          # Check if new features have corresponding tests
          CHANGED_FILES=$(git diff --name-only ${{ github.event.before }}..${{ github.sha }} | grep -E '\.(py)$' | grep -E 'services/|features/' || true)

          if [ -n "$CHANGED_FILES" ]; then
            echo "Changed service files detected:"
            echo "$CHANGED_FILES"

            MISSING_TESTS=""
            for file in $CHANGED_FILES; do
              # Skip __init__.py and test files
              if [[ "$file" == *"__init__.py" ]] || [[ "$file" == *"test_"* ]]; then
                continue
              fi

              # Convert service file path to expected test file path
              TEST_FILE=$(echo "$file" | sed 's|services/|tests/unit/services/|' | sed 's|\.py$|_test.py|' | sed 's|/\([^/]*\)_test\.py$|/test_\1.py|')

              if [ ! -f "$TEST_FILE" ]; then
                MISSING_TESTS="$MISSING_TESTS\n$TEST_FILE"
              fi
            done

            if [ -n "$MISSING_TESTS" ]; then
              echo "❌ Missing test files:"
              echo -e "$MISSING_TESTS"
              echo "::error::Feature Testing Rule violated: All new service code must have corresponding tests"
              exit 1
            else
              echo "✅ All service files have corresponding tests"
            fi
          else
            echo "No service files changed"
          fi

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: test-validation
    strategy:
      matrix:
        python-version: ['3.11', '3.12']

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt', 'requirements-ci.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-ci.txt
          pip install pytest-cov pytest-xdist pytest-timeout

      - name: Run unit tests with coverage
        run: |
          pytest tests/unit/ \
            -v \
            --cov=services \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-fail-under=80 \
            --maxfail=5 \
            --timeout=300 \
            --durations=10 \
            -n auto

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U test_user -d test_db"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('requirements.txt', 'requirements-ci.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-ci.txt
          pip install pytest-asyncio pytest-timeout

      - name: Wait for services
        run: |
          # Wait for Redis
          timeout 30s bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
          # Wait for PostgreSQL
          timeout 30s bash -c 'until pg_isready -h localhost -p 5432 -U test_user; do sleep 1; done'

      - name: Run integration tests
        run: |
          pytest tests/integration/ \
            -v \
            --timeout=600 \
            --maxfail=3 \
            --durations=10
        env:
          REDIS_URL: redis://localhost:6379/0
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          TESTING: true

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-e2e-${{ hashFiles('requirements.txt', 'requirements-ci.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-ci.txt
          pip install pytest-asyncio pytest-timeout

      - name: Create test environment file
        run: |
          cat > .env.test << EOF
          ENVIRONMENT=test
          DEBUG=false
          REDIS_URL=redis://localhost:6379/0
          DATABASE_URL=postgresql://test_user:test_password@localhost:5432/test_db
          JWT_SECRET_KEY=test_secret_key_for_testing_only
          API_HOST=0.0.0.0
          API_PORT=8000
          EOF

      - name: Start services with Docker Compose
        run: |
          # Copy test environment
          cp .env.test .env

          # Start all services
          docker-compose up -d

          # Wait for services to be healthy
          echo "Waiting for services to start..."
          sleep 60

          # Check service health
          timeout 120s bash -c 'until curl -f http://localhost:8000/health > /dev/null 2>&1; do
            echo "Waiting for API service...";
            sleep 5;
          done'

      - name: Run E2E tests
        run: |
          pytest tests/e2e/ \
            -v \
            --timeout=1200 \
            --maxfail=1 \
            --durations=10 \
            --tb=short
        env:
          API_BASE_URL: http://localhost:8000
          TESTING: true

      - name: Collect Docker logs on failure
        if: failure()
        run: |
          echo "=== Docker Compose Services Status ==="
          docker-compose ps

          echo "=== API Service Logs ==="
          docker-compose logs control

          echo "=== LLM Service Logs ==="
          docker-compose logs llm_service

          echo "=== Job Manager Logs ==="
          docker-compose logs job_manager

          echo "=== Embedding Server Logs ==="
          docker-compose logs embedding_server

      - name: Stop services
        if: always()
        run: |
          docker-compose down -v
          docker system prune -f

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-ci.txt
          pip install locust memory-profiler psutil

      - name: Run performance tests
        run: |
          pytest tests/performance/ \
            -v \
            --timeout=1800 \
            --durations=10
        env:
          PERFORMANCE_TESTING: true

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: |
            tests/performance/results/
            *.prof

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: test-validation

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security testing tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety semgrep
          pip install -r requirements.txt

      - name: Run Bandit security scan
        run: |
          bandit -r services/ -f json -o bandit-report.json || true
          bandit -r services/ --severity-level medium

      - name: Run Safety check
        run: |
          safety check --json --output safety-report.json || true
          safety check

      - name: Run Semgrep security scan
        run: |
          semgrep --config=auto services/ --json --output=semgrep-report.json || true
          semgrep --config=auto services/

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            semgrep-report.json

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, security-tests]
    if: always()

    steps:
      - name: Test Results Summary
        run: |
          echo "# 🧪 Feature Testing Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.unit-tests.result }}" == "success" ]; then
            echo "✅ **Unit Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Unit Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.integration-tests.result }}" == "success" ]; then
            echo "✅ **Integration Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Integration Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
            echo "✅ **E2E Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **E2E Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.security-tests.result }}" == "success" ]; then
            echo "✅ **Security Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Security Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📊 Test Coverage Requirements" >> $GITHUB_STEP_SUMMARY
          echo "- **Minimum Coverage**: 80%" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Types Required**: Unit, Integration, E2E" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Scans**: Bandit, Safety, Semgrep" >> $GITHUB_STEP_SUMMARY

      - name: Fail if critical tests failed
        if: needs.unit-tests.result == 'failure' || needs.integration-tests.result == 'failure' || needs.e2e-tests.result == 'failure'
        run: |
          echo "❌ Critical tests failed! Please fix before merging."
          exit 1
